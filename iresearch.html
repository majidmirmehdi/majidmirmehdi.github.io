<!DOCTYPE html>
<head>
<title>Professor Majid Mirmehdi</title>
</head>

<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body {
  margin: 0;
  font-family: Arial, Helvetica, sans-serif;
}

.topnav {
  overflow: auto;
  background-color: #ccc;
}

.topnav a {
  float: left;
  color: #222222;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #eee;
  color: black;
}

.topnav a.active {
  background-color: #eeeeee;
  color: black;
}
</style>
</head>

<body>

<div class="topnav">
  <a class="active" href="index.html">Home</a>
  <a href="iresearch.html">Research</a>
  <a href="https://scholar.google.co.uk/citations?user=NsW3yAwAAAAJ&hl=en">Publications</a>
  <a href="iteach.html">Teaching</a>
  <a href="iact.html">Activities</a>
  <a href="iteam.html">RAs & Students</a>
  <a href="https://vilab.blogs.bristol.ac.uk/">VI-Lab</a>
</div>



<TABLE>
<TD> <IMG SRC="./MMphoto.jpg" width=180 ALT="Majid Mirmehdi", ALIGN=LEFT>
<TD>
<dl>
<dd><h2>Prof. Majid Mirmehdi</h2>
<h3>Professor of Computer Vision</h3>
<dd><h3>Fellow IAPR, BMVA Distinguished Fellow</h3>
<dd><a href="https://vilab.blogs.bristol.ac.uk/">Visual Information Laboratory</a>
<dd><a href="http://www.cs.bris.ac.uk/">Department of Computer Science</a>
<dd><a href="http://www.bris.ac.uk/"> University of Bristol</a>
<dd><a href="http://www.cs.bris.ac.uk/Research/Vision/mvb.html">Merchant Venturers Building</a>
<dd>Woodland Road, <a href="http://www.brisindex.co.uk/">Bristol</a> BS8 1UB, <a href="http://www.uktravel.com/index.html">UK</a>
<dd>Tel: +44 (0)117-954 5139 , Fax: +44 (0)117-954 5208
<dd>Email: <a href="mailto:M.Mirmehdi@cs.bris.ac.uk">M.Mirmehdi@cs.bris.ac.uk</a> </b>
<dd>ORCID:<a href="https://orcid.org/0000-0002-6478-1403">0000-0002-6478-1403/a> </b>
</dl>
<TD>   </TD>
<TD>   </TD>
<TD>   </TD>
 <TD> <a href="http://www.iapr.org"><img src="./IAPRLogo_fellowRev.gif"  alt="IAPR Fellow" border="0" height="90"  width="180" align="right"></a>
</TABLE>

<!--
<IMG SRC="newanim.gif" ALT="NEW", ALIGN=LEFT> <a href="http://www.cs.bris.ac.uk/admissions/phd/news-item.jsp?nid=19">PhD Studentship available:</a> please note the strict eligibility criteria.
<hr noshade>
-->
<b><font color=green> Notice </font>- I am unable to offer Summer internships to overseas undergrduates, self-funded or otherwise.
</b>

<hr size="1">
         <a href="http://irc-sphere.ac.uk">SPHERE</a> | PD Sensors |


 <hr size="1">
    <h2>Selection of Research Projects</h2>

       <h3><em>Updates in progress...</em></h3>

       <!-- <h3>Prediction of Thrombectomy Outcome</h3>
       <img src="ThrombectomyNetwork.jpg" width="250"/>
       <p>A study of analysis of 3D NCCT scans and clinical metadata to predict the outcomes of thrombectomy procedure
       <p>Paper due soon in 2020 -->
  <!--     <style>
       #myHeader {
         background-color: lightblue;
         color: black;
         padding: 40px;
         text-align: center;
       }
       </style>
       <h3>id="myHeader"> Multi-modal Signals for Subject Re-Id in Multi-Person Environments</h3>
-->

       <h3> Multi-modal Signals for Subject Re-Id in Multi-Person Environments</h3>
       <TABLE>
         <TD><img src="cvpm2019.png" height="120", ALIGN=LEFT/>
         <TD>
         <DL>
          <DD> Who Goes There? Exploiting Silhouettes and Wearable Signals for Subject Identification in Multi-Person Environments,
          A Masullo, T Burghardt, D Damen, T Perrett, M Mirmehdi. <em>2nd Int. Workshop on Computer Vision for Physiological Measurement (CVPM) at IEEE International Conference of Computer Vision (ICCVW),</em>  2019.
          <DD><a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVPM/Masullo_Who_Goes_There_Exploiting_Silhouettes_and_Wearable_Signals_for_Subject_ICCVW_2019_paper.pdf" target="_blank">CVF Version</a> | <a href="https://doi.org/10.5523/bris.1gt0wgkqgljn21jjgqoq8enprr" target="_blank">Dataset: SPHERE-Calorie</a>
        </DL>
        </TABLE>


      <h3>What`s cooking and Why? Behaviour Recognition during Unscripted Cooking Tasks</h3>
      <TABLE>
          <TD><img src="cookingbehaviour.png" width="320" height=150/>
          <TD>
          <DL>
            <DD> Analysing Cooking Behaviour in Home Settings: Towards Health Monitoring. K Yordanova, S Ludtke, S Whitehouse, F Kruger, A Paiement, M Mirmehdi, I Craddock, T Kirste. <em>Sensors</em>, 19(3), 646, 2019
            <DD> <a href="https://www.mdpi.com/1424-8220/19/3/646" target="_blank">Link to PDF</a>
        <!-- <p> Evaluation of cupboard door sensors for improving activity recognition in the kitchen. S. Whitehouse, K. Yordanova, S. Ludtke, A. Paiement and M. Mirmehdi, pp. 167-17, 2018 <p> https://ieeexplore.ieee.org/document/8480352 PDF -->
            <p><DD> What is cooking and Why? Behaviour Recognition during Unscripted Cooking Tasks for Health Monitoring. K Yordanova, S Whitehouse, A Paiement, M Mirmehdi, T Kirste, I Craddock. <em>PerCom</em> 2017 (Best work in progress paper award)
            <DD><a href="https://www.researchgate.net/publication/312056108_What's_cooking_and_Why_Behaviour_Recognition_during_Unscripted_Cooking_Tasks_for_Health_Monitoring">Link to PDF</a> | <a href="https://data.bris.ac.uk/data/dataset/raqa2qzai45z15b4n0za94toi"> Dataset: SPHERE Unscripted kitchen activities </a>
        </DL>
      </TABLE>



    <h3>Great Ape Detection and Identification</h3>
    <TABLE>
        <TD><img src="ApeOverview2019.jpg" height="210" width="320"/>
        <TD>
        <DL>
          <DD> Great Ape Detection in Challenging Jungle Camera Trap Footage via Attention-Based Spatial and Temporal Feature Blending, X. Yang, M. Mirmehdi, T. Burghardt, <em> Computer Vision for Wildlife Conservation (CVWC) Workshop at
       IEEE International Conference of Computer Vision (ICCVW) </em>,  2019.
          <DD> <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/CVWC/Yang_Great_Ape_Detection_in_Challenging_Jungle_Camera_Trap_Footage_via_ICCVW_2019_paper.pdf">CVF Version</a> |
          <a href="https://arxiv.org/abs/1908.11240" target="_blank">Arxiv PDF</a> |
          <a href="http://people.cs.bris.ac.uk/~burghard/mpi2019.txt" target="_blank">Dataset PanAfrican2019 Video</a>  |
          <a href="https://doi.org/10.5523/bris.1v9op9lc6zi5g25kkwa5smb3vq" target="_blank">Dataset: PanAfrican2019 Annotations and Code</a>
        </DL>
      </TABLE>



    <h3>Action Completion: Detection & Recognition</h3>
    <TABLE>
        <TD><a href="http://people.cs.bris.ac.uk/~damen/ActionCompletion/"><img src="ActionCompletionDetectionIntro.png" height="220" width=320"/></a>
        <TD>
        <DL>
          <DD>Weakly-Supervised Completion Moment Detection using Temporal Attention. F Heidarivincheh, M Mirmehdi, D Damen. <em> ICCV Workshop on Human Behaviour Understanding</em>, 2019
          <DD> <a href="https://arxiv.org/abs/1910.09920">Arxiv PDF</a> | <a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/HBU/Heidarivincheh_Weakly-Supervised_Completion_Moment_Detection_using_Temporal_Attention_ICCVW_2019_paper.pdf">CVF PDF</a>
          <p><DD>Action Completion: A Temporal Model for Moment Detection. F Heidarivincheh, M Mirmehdi, D Damen. <em>BMVC</em>, 2018
          <DD><a href="https://arxiv.org/abs/1805.06749">Arxiv PDF</a> | <a href="https://youtu.be/Hrxehk3Sutc">Video2018</a> | <a href="https://github.com/FarnooshHeidari/CompletionDetection">Dataset</a>
          <p><DD>Beyond Action Recognition: Action Completion in RGB-D Data. F Heidarivincheh, M Mirmehdi, D Damen. <em> BMVC</em>, 2016
          <DD><a href="http://people.cs.bris.ac.uk/~damen/ActionCompletion/ActionCompletion_BMVC2016.pdf">pdf</a> | <a href="http://people.cs.bris.ac.uk/~damen/ActionCompletion/ActionCompletion_BMVC2016_abstract.pdf">abstract</a> | <a href="https://youtu.be/iBdW-kVKMds">Video2016</a> | <a href="http://dx.doi.org/10.5523/bris.66qry08cv1fj1eunwxwob3fjz">Dataset: RGBD-Action-Completion-2016</a>
       </DL>
    </TABLE>


    <h3>Calorie Expenditure Estimation for Health Monitoring</h3>
    <TABLE>
       <TD><img src="CalorieOld.png" width="320"/>
       <TD>
       <DL>
        <DD> CaloriNet: From silhouettes to calorie estimation in private environments. A Masullo, T Burghardt, D Damen, S Hannuna, V Ponce-Lopez, M Mirmehdi, <em> BMVC</em> 2018
        <DD> <a href="http://bmvc2018.org/contents/papers/0383.pdf">PDF</a>  | <a href="https://github.com/ale152/CaloriNet"> Code on Github</a>
        <p><DD> Energy expenditure estimation using visual and inertial sensors. L Tao, T Burghardt, M Mirmehdi, D Damen, A. Cooper, S. Hannuna, M Camplani, A. Paiement, I Craddock. <em> IET Computer Vision</em>, 12(1), 2018.
        <DD> <a href="https://digital-library.theiet.org/content/journals/10.1049/iet-cvi.2017.0112">OA PDF @IET</a>  | <a href="https://www.irc-sphere.ac.uk/work-package-2/calorie"> SPHERE Webpage</a>
       <!-- <p> Calorie Counter: RGB-Depth Visual Estimation of Energy Expenditure at Home. L Tao, T Burghardt, M Mirmehdi, D Damen, A. Cooper, S. Hannuna, M Camplani, A. Paiement, I Craddock. ACCV Workshops pp 239-251, 2016.
        <DD> <a href="https://link.springer.com/chapter/10.1007/978-3-319-54407-6_16">Link to PDF</a> |
          <a href="https://data.bris.ac.uk/data/dataset/1gt0wgkqgljn21jjgqoq8enprr">Dataset: SPHERE-Calorie</a>  | <a href="https://www.irc-sphere.ac.uk/work-package-2/calorie"> SPHERE Webpage</a> -->
     </DL>
   </TABLE>


    <h3>Acquisition and registration of point clouds using two facing Kinects </h3>
    <TABLE>
       <TD><img src="TwoKinectSynch.gif" height="220" width=320"/>
       <TD>
       <DL>
       <DD> 3D Data Acquisition and Registration using Two Opposing Kinects. V Soleimani, M Mirmehdi, D Damen, S Hannuna, M Camplani, <em>4th International Conference on 3D Vision (3DV)</em>, 128-137, 2016
       <DD> <a href="https://ieeexplore.ieee.org/abstract/document/7785085"> PDF@ieeexplore </a> | <a href="https://github.com/BristolVisualPFT/3D_Data_Acquisition_Registration_Using_Kinects/tree/master/Double_opposing_Kinects"> Code</a>
       </DL>
    </TABLE>


    <h3><a href="http://www.irc-sphere.ac.uk/work-package-2/DS-KCF">DS-KCF: Depth-Based Real-Time Single Object Tracker</a></h3>
    <TABLE>
       <TD><img src="DSKCF.png" height="220" width=320"/>
       <TD>
       <DL>
        <DD>Real-time RGB-D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling. M Camplani, S Hannuna, M Mirmehdi, D Damen, L Tao, T Burghardt and A Paiment. British Machine Vision Conference (BMVC), Sep 2015.
        <DD>  <a href="http://bmvc2015.swansea.ac.uk/proceedings/papers/paper145/paper145.pdf">PDF</a> |
              <a href="https://www.youtube.com/watch?v=yhT2PdN9BTw&amp;feature=youtu.be">Video 1</a> |
              <a href="https://www.youtube.com/watch?v=YoFMf2iARzA&amp;feature=youtu.be">Video 2</a> |
              <a href="http://data.bris.ac.uk/data/dataset/16vbnj3im1ygi1sh0yd0mt4lp0">Code on Github</a>
        </DL>
     </TABLE>


    <h3><a href="http://www.irc-sphere.ac.uk/work-package-2/movement-quality">Online Quality Assessment for Human Motion</a></h3>
    <TABLE>
        <TD><img src="Quality.png" height="220" width=320">
          <TD>
          <DL>
          <DD>Online quality assessment of human movement from skeleton data. A Paiment, L Tao, S Hannuna, M Camplani, D Damen and M Mirmehdi. British Machine Vision Conference (BMVC), Sep 2014.
          <DD><a href="http://www.cs.bris.ac.uk/home/palement/articles/bmvc2014.pdf">PDF</a> | <a href="http://data.bris.ac.uk/data/dataset/bgresiy3olk41nilo7k6xpkqf">Dataset</a> | <a href="http://www.cs.bris.ac.uk/home/palement/datasets/code_movement_quality.zip">Code</a></p>
       </DL>
    </TABLE>


     <h3><a href="http://www.amazon.co.uk/HANDBOOK-TEXTURE-ANALYSIS-MIRMEHDI-MAJID/dp/1848161158/ref=sr_1_1?ie=UTF8&s=books&qid=1245248607&sr=1-1" target="new"> Handbook of Texture Analysis </a> </h3>
     <TABLE>
        <TD><a href="http://www.amazon.co.uk/HANDBOOK-TEXTURE-ANALYSIS-MIRMEHDI-MAJID/dp/1848161158/ref=sr_1_1?ie=UTF8&s=books&qid=1245248607&sr=1-1" target="new"> <img alt="Handbook of Texture Analysis" border="0" src="frontcoverTexture.jpg" width="120" align="right"></a>
        <TD>
        <DL>
         <DD> Collection of chapters on many aspects of texture analysis (pre-deep learning era!)
         <DD> Hardcover: 424 pages - Publisher: Imperial College Press (Dec. 2008) - ISBN-13: 978-1848161153
         <DD> <a href="http://www.cs.bris.ac.uk/Publications/pub_master.jsp?id=2000853">Sample chapter: A Galaxy of Texture Features</a>
      </DL>
      </TABLE>



 <hr size="1">
<p><em>Last Updated Feb. 2020</em> </p>


</body>
</html>
